
# ğŸ¤– Proyecto de Aprendizaje Supervisado para ClasificaciÃ³n

## ğŸ“ MaestrÃ­a en Ciencia de Datos e Inteligencia Artificial  
**MÃ³dulo:** Machine Learning and Deep Learning  
**Docente:** M.Sc. Renzo Claure Aracena  
**Grupo 5:**
- Patricia Aguilar Cabrera  
- David Aliaga Nina  
- Harold Aponte ZuÃ±iga  
- RubÃ©n Baltazar Balderrama  
- Jhonny GarcÃ­a Zelaya  
---

## 1. ğŸ§© DefiniciÃ³n del Problema

El presente proyecto tiene como finalidad construir un modelo de clasificaciÃ³n binaria utilizando tÃ©cnicas de aprendizaje supervisado.  
La variable objetivo es `OBJ`, con valores `'SI'` y `'NO'`. El dataset incluye 30 variables independientes, disponibles en formato absoluto (`V1` a `V31`) y relativo (`V1_P` a `V31_P`).

> âš ï¸ Se decide trabajar solo con las **variables absolutas**, debido a la **baja varianza** observada en las variables relativas.

---

## 2. ğŸ§¾ DescripciÃ³n del Dataset

ğŸ“‚ **Fuente de datos:** Archivo `.csv` delimitado por `|`  
ğŸ”¢ **Total de registros:** 3,152 observaciones  
ğŸ“Œ **CaracterÃ­sticas:**

| Tipo de variable        | DescripciÃ³n                                 |
|-------------------------|---------------------------------------------|
| `OBJ`                   | Variable objetivo binaria (`SI` / `NO`)     |
| `V1` a `V31`            | Variables absolutas                         |
| `V1_P` a `V31_P`        | Variables relativas (descartadas)           |

---

## 3. ğŸ”§ Preprocesamiento de Datos

âœ”ï¸ Renombrado de columna duplicada `V31_P` â†’ `V31`  
âœ”ï¸ SelecciÃ³n de columnas: `V1` a `V31` + `OBJ`  
âœ”ï¸ ConversiÃ³n de `OBJ`:  
- `SI` â†’ 1  
- `NO` â†’ 0  
âœ”ï¸ ValidaciÃ³n de datos nulos (no se encontraron)  
âœ”ï¸ EstandarizaciÃ³n de variables mediante `StandardScaler`

---

## 4. ğŸ§ª SelecciÃ³n de Variables Relevantes

Se aplicÃ³ la prueba estadÃ­stica **Chi-cuadrado** para determinar la relaciÃ³n entre cada variable independiente (`V1` a `V31`) y la variable objetivo (`OBJ`). Este test evalÃºa la independencia entre las variables categÃ³ricas y permite filtrar aquellas que presentan una relaciÃ³n estadÃ­sticamente significativa.

### ğŸ”¹ Procedimiento:

1. Para cada variable `Vi`, se generÃ³ una tabla de contingencia con la variable `OBJ`.
2. Se aplicÃ³ `chi2_contingency` de `scipy.stats` para obtener el valor p.
3. Se seleccionaron aquellas variables con **valor p < 0.05**, lo que indica dependencia estadÃ­stica con la variable objetivo.

ğŸ“Œ **Variables seleccionadas:**  
`V3, V4, V5, V7, V9, V10, V12, V14, V15, V17, V19, V20, V21, V22, V24, V26, V27, V29, V30, V31`

---

## 5. âš™ï¸ Entrenamiento de Modelos de ClasificaciÃ³n

Utilizando las variables seleccionadas por Chi-cuadrado, se entrenaron mÃºltiples algoritmos de clasificaciÃ³n supervisada.  
Los datos fueron divididos en conjuntos de entrenamiento y prueba (80/20), y las variables fueron previamente estandarizadas con `StandardScaler`.

### ğŸ”¸ Modelos aplicados:

- RegresiÃ³n LogÃ­stica
- K-Nearest Neighbors (KNN)
- Ãrbol de DecisiÃ³n
- Random Forest
- XGBoost
- Support Vector Machine (SVM)

---

## 6. ğŸ” ValidaciÃ³n Cruzada y Ajuste de HiperparÃ¡metros

Se utilizÃ³ `GridSearchCV` con validaciÃ³n cruzada de 5 pliegues para optimizar los hiperparÃ¡metros de los modelos con mejor rendimiento.

### ğŸ”¹ Random Forest
- `n_estimators`: [100, 200, 300]
- `max_depth`: [None, 10, 20]

### ğŸ”¹ SVM
- `C`: [0.1, 1, 10]
- `kernel`: ['linear', 'rbf']

---

## 7. ğŸ“ˆ EvaluaciÃ³n de Modelos

### ğŸ”¸ MÃ©tricas utilizadas:
- Accuracy
- Precision
- Recall
- F1-Score
- ROC-AUC

ğŸ“Š **Resultado destacado:**  
El modelo **Random Forest** presentÃ³ el mejor rendimiento global, alcanzando un **F1-Score de 0.89**, ademÃ¡s de valores superiores de precisiÃ³n y recall frente a los demÃ¡s modelos.

---

## 8. ğŸ¥‡ Modelo Seleccionado

### âœ”ï¸ Modelo Final: `RandomForestClassifier`

ğŸ”§ **ParÃ¡metros Ã³ptimos encontrados:**
- `n_estimators = 200`
- `max_depth = 20`

ğŸ“Œ **JustificaciÃ³n tÃ©cnica:**
- Mejor equilibrio entre precisiÃ³n y recall (F1-score).
- Alta capacidad de generalizaciÃ³n.
- Robustez ante variables irrelevantes y colinealidad.
- Bajo riesgo de sobreajuste.

---

## 9. ğŸ“Œ Conclusiones

- La prueba de **Chi-cuadrado** fue efectiva para seleccionar un subconjunto relevante de variables.
- La combinaciÃ³n de **preprocesamiento adecuado + selecciÃ³n de variables + validaciÃ³n cruzada** condujo a resultados Ã³ptimos.
- **Random Forest** fue el modelo que mejor se adaptÃ³ al problema de clasificaciÃ³n binaria, combinando interpretabilidad, precisiÃ³n y estabilidad.

---
